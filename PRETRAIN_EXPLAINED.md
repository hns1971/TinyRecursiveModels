# pretrain.py è¯¦ç»†è§£æ

è¿™æ˜¯ TRM é¡¹ç›®çš„æ ¸å¿ƒè®­ç»ƒè„šæœ¬ï¼Œä½¿ç”¨ Hydra è¿›è¡Œé…ç½®ç®¡ç†ï¼Œæ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒã€EMAã€è¯„ä¼°ç­‰åŠŸèƒ½ã€‚

## ğŸ“‹ ç›®å½•ç»“æ„

1. [é…ç½®ç±»å®šä¹‰](#é…ç½®ç±»å®šä¹‰)
2. [æ ¸å¿ƒæ•°æ®ç»“æ„](#æ ¸å¿ƒæ•°æ®ç»“æ„)
3. [æ•°æ®åŠ è½½](#æ•°æ®åŠ è½½)
4. [æ¨¡å‹åˆ›å»º](#æ¨¡å‹åˆ›å»º)
5. [è®­ç»ƒæµç¨‹](#è®­ç»ƒæµç¨‹)
6. [è¯„ä¼°æµç¨‹](#è¯„ä¼°æµç¨‹)
7. [ä¸»å‡½æ•°](#ä¸»å‡½æ•°)

---

## é…ç½®ç±»å®šä¹‰

### 1. LossConfig / ArchConfig / EvaluatorConfig

```python
class LossConfig(pydantic.BaseModel):
    name: str  # æŸå¤±å‡½æ•°ç±»åï¼Œå¦‚ "losses@ACTLossHead"
    
class ArchConfig(pydantic.BaseModel):
    name: str  # æ¨¡å‹æ¶æ„ç±»åï¼Œå¦‚ "recursive_reasoning.trm@TinyRecursiveReasoningModel_ACTV1"
    loss: LossConfig
    
class EvaluatorConfig(pydantic.BaseModel):
    name: str  # è¯„ä¼°å™¨ç±»åï¼Œå¦‚ "arc@ARC"
```

**ä½œç”¨**ï¼šä½¿ç”¨ Pydantic è¿›è¡Œç±»å‹éªŒè¯å’Œé…ç½®ç®¡ç†ï¼Œæ”¯æŒ `extra='allow'` ä»¥å…è®¸é¢å¤–å‚æ•°ã€‚

### 2. PretrainConfig

```44:84:pretrain.py
class PretrainConfig(pydantic.BaseModel):
    # Config
    arch: ArchConfig
    # Data
    data_paths: List[str]
    data_paths_test: List[str] = []
    # Evaluators
    evaluators: List[EvaluatorConfig] = []

    # Hyperparams
    global_batch_size: int
    epochs: int

    lr: float
    lr_min_ratio: float
    lr_warmup_steps: int

    weight_decay: float
    beta1: float
    beta2: float

    # Puzzle embedding
    puzzle_emb_lr: float
    puzzle_emb_weight_decay: float

    # Names
    project_name: Optional[str] = None
    run_name: Optional[str] = None
    load_checkpoint: Optional[str] = None
    checkpoint_path: Optional[str] = None

    # Extras
    seed: int = 0
    checkpoint_every_eval: bool = False
    eval_interval: Optional[int] = None
    min_eval_interval: Optional[int] = 0 # when to start eval
    eval_save_outputs: List[str] = []

    ema: bool = False # use Exponential-Moving-Average
    ema_rate: float = 0.999 # EMA-rate
    freeze_weights: bool = False # If True, freeze weights and only learn the embeddings
```

**å…³é”®å‚æ•°è¯´æ˜**ï¼š
- `data_paths`: è®­ç»ƒæ•°æ®é›†è·¯å¾„åˆ—è¡¨
- `data_paths_test`: æµ‹è¯•æ•°æ®é›†è·¯å¾„ï¼ˆå¯é€‰ï¼‰
- `global_batch_size`: å…¨å±€æ‰¹æ¬¡å¤§å°ï¼ˆåœ¨å¤š GPU æ—¶ä¼šè‡ªåŠ¨åˆ†é…åˆ°å„ GPUï¼‰
- `eval_interval`: æ¯ N ä¸ª epoch è¯„ä¼°ä¸€æ¬¡
- `ema`: æ˜¯å¦ä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆé€šå¸¸èƒ½æå‡æ¨¡å‹æ€§èƒ½ï¼‰

---

## æ ¸å¿ƒæ•°æ®ç»“æ„

### TrainState

```86:94:pretrain.py
@dataclass
class TrainState:
    model: nn.Module
    optimizers: Sequence[torch.optim.Optimizer]
    optimizer_lrs: Sequence[float]
    carry: Any

    step: int
    total_steps: int
```

**ä½œç”¨**ï¼šä¿å­˜è®­ç»ƒçŠ¶æ€
- `carry`: æ¨¡å‹çš„çŠ¶æ€ï¼ˆç”¨äºé€’å½’æ¨ç†ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¿æŒï¼‰
- `step`: å½“å‰è®­ç»ƒæ­¥æ•°
- `total_steps`: æ€»è®­ç»ƒæ­¥æ•°ï¼ˆæ ¹æ® epochs å’Œæ•°æ®é›†å¤§å°è®¡ç®—ï¼‰

---

## æ•°æ®åŠ è½½

### create_dataloader

```97:113:pretrain.py
def create_dataloader(config: PretrainConfig, split: str, rank: int, world_size: int, **kwargs):
    dataset = PuzzleDataset(PuzzleDatasetConfig(
        seed=config.seed,
        dataset_paths=config.data_paths_test if len(config.data_paths_test)>0 and split=="test" else config.data_paths,
        rank=rank,
        num_replicas=world_size,
        **kwargs
    ), split=split)
    dataloader = DataLoader(
        dataset,
        batch_size=None,
        num_workers=1,
        prefetch_factor=8,
        pin_memory=True,
        persistent_workers=True
    )
    return dataloader, dataset.metadata
```

**åŠŸèƒ½**ï¼š
1. åˆ›å»º `PuzzleDataset`ï¼ˆæ”¯æŒåˆ†å¸ƒå¼æ•°æ®åˆ†ç‰‡ï¼‰
2. é…ç½® DataLoaderï¼ˆ`batch_size=None` å› ä¸ºæ•°æ®é›†è‡ªå·±å¤„ç†æ‰¹æ¬¡ï¼‰
3. è¿”å›æ•°æ®åŠ è½½å™¨å’Œå…ƒæ•°æ®

**åˆ†å¸ƒå¼æ”¯æŒ**ï¼š
- `rank`: å½“å‰è¿›ç¨‹çš„ rankï¼ˆ0 åˆ° world_size-1ï¼‰
- `num_replicas`: æ€»è¿›ç¨‹æ•°
- æ¯ä¸ªè¿›ç¨‹åªåŠ è½½åˆ†é…ç»™å®ƒçš„æ•°æ®åˆ†ç‰‡

---

## æ¨¡å‹åˆ›å»º

### create_model

```116:192:pretrain.py
def create_model(config: PretrainConfig, train_metadata: PuzzleDatasetMetadata, rank: int, world_size: int):
    model_cfg = dict(
        **config.arch.__pydantic_extra__,  # type: ignore
        batch_size=config.global_batch_size // world_size,
        vocab_size=train_metadata.vocab_size,
        seq_len=train_metadata.seq_len,
        num_puzzle_identifiers=train_metadata.num_puzzle_identifiers,
        causal=False  # Non-autoregressive
    )

    # Instantiate model with loss head
    model_cls = load_model_class(config.arch.name)
    loss_head_cls = load_model_class(config.arch.loss.name)

    with torch.device("cuda"):
        model: nn.Module = model_cls(model_cfg)
        print(model)
        model = loss_head_cls(model, **config.arch.loss.__pydantic_extra__)  # type: ignore
        if "DISABLE_COMPILE" not in os.environ:
            model = torch.compile(model)  # type: ignore

        # Load checkpoint
        if rank == 0:
            load_checkpoint(model, config)

        # Broadcast parameters from rank 0
        if world_size > 1:
            with torch.no_grad():
                for param in list(model.parameters()) + list(model.buffers()):
                    dist.broadcast(param, src=0)

    # Optimizers and lr
    if config.arch.puzzle_emb_ndim == 0:
        optimizers = [
            AdamATan2(
                model.parameters(),
                lr=0,  # Needs to be set by scheduler
                weight_decay=config.weight_decay,
                betas=(config.beta1, config.beta2)
            )
        ]
        optimizer_lrs = [
            config.lr
        ]
    elif config.freeze_weights:
        optimizers = [
            CastedSparseEmbeddingSignSGD_Distributed(
                model.model.puzzle_emb.buffers(),  # type: ignore
                lr=0,  # Needs to be set by scheduler
                weight_decay=config.puzzle_emb_weight_decay,
                world_size=world_size
            )
        ]
        optimizer_lrs = [
            config.puzzle_emb_lr
        ]
    else:
        optimizers = [
            CastedSparseEmbeddingSignSGD_Distributed(
                model.model.puzzle_emb.buffers(),  # type: ignore
                lr=0,  # Needs to be set by scheduler
                weight_decay=config.puzzle_emb_weight_decay,
                world_size=world_size
            ),
            AdamATan2(
                model.parameters(),
                lr=0,  # Needs to be set by scheduler
                weight_decay=config.weight_decay,
                betas=(config.beta1, config.beta2)
            )
        ]
        optimizer_lrs = [
            config.puzzle_emb_lr,
            config.lr
        ]

    return model, optimizers, optimizer_lrs
```

**å…³é”®æ­¥éª¤**ï¼š

1. **æ„å»ºæ¨¡å‹é…ç½®**ï¼š
   - ä» `config.arch` æå–æ‰€æœ‰é¢å¤–å‚æ•°
   - è®¾ç½®æ‰¹æ¬¡å¤§å°ï¼ˆå…¨å±€æ‰¹æ¬¡å¤§å°é™¤ä»¥ GPU æ•°é‡ï¼‰
   - è®¾ç½®è¯æ±‡è¡¨å¤§å°ã€åºåˆ—é•¿åº¦ç­‰

2. **åŠ¨æ€åŠ è½½æ¨¡å‹ç±»**ï¼š
   - `load_model_class()` æ ¹æ®å­—ç¬¦ä¸²åç§°åŠ è½½æ¨¡å‹ç±»ï¼ˆå¦‚ `"recursive_reasoning.trm@TinyRecursiveReasoningModel_ACTV1"`ï¼‰
   - å…ˆåˆ›å»ºæ¨¡å‹ï¼Œå†åŒ…è£…æŸå¤±å‡½æ•°å¤´

3. **torch.compile**ï¼š
   - å¦‚æœæœªè®¾ç½® `DISABLE_COMPILE` ç¯å¢ƒå˜é‡ï¼Œä¼šç¼–è¯‘æ¨¡å‹ä»¥åŠ é€Ÿ

4. **åˆ†å¸ƒå¼åŒæ­¥**ï¼š
   - Rank 0 åŠ è½½æ£€æŸ¥ç‚¹
   - ç„¶åå¹¿æ’­å‚æ•°åˆ°æ‰€æœ‰è¿›ç¨‹

5. **ä¼˜åŒ–å™¨é…ç½®**ï¼š
   - **æƒ…å†µ 1**ï¼šæ—  puzzle embedding â†’ åªç”¨ AdamATan2
   - **æƒ…å†µ 2**ï¼šå†»ç»“æƒé‡ â†’ åªç”¨ SignSGD è®­ç»ƒ puzzle embedding
   - **æƒ…å†µ 3**ï¼šæ­£å¸¸è®­ç»ƒ â†’ ä¸¤ä¸ªä¼˜åŒ–å™¨ï¼ˆpuzzle embedding + æ¨¡å‹æƒé‡ï¼‰

---

## è®­ç»ƒæµç¨‹

### train_batch

```289:343:pretrain.py
def train_batch(config: PretrainConfig, train_state: TrainState, batch: Any, global_batch_size: int, rank: int, world_size: int):
    train_state.step += 1
    if train_state.step > train_state.total_steps:  # At most train_total_steps
        return

    # To device
    batch = {k: v.cuda() for k, v in batch.items()}

    # Init carry if it is None
    if train_state.carry is None:
        with torch.device("cuda"):
            train_state.carry = train_state.model.initial_carry(batch)  # type: ignore

    # Forward
    train_state.carry, loss, metrics, _, _ = train_state.model(carry=train_state.carry, batch=batch, return_keys=[])

    ((1 / global_batch_size) * loss).backward()

    # Allreduce
    if world_size > 1:
        for param in train_state.model.parameters():
            if param.grad is not None:
                dist.all_reduce(param.grad)
            
    # Apply optimizer
    lr_this_step = None    
    for optim, base_lr in zip(train_state.optimizers, train_state.optimizer_lrs):
        lr_this_step = compute_lr(base_lr, config, train_state)

        for param_group in optim.param_groups:
            param_group['lr'] = lr_this_step
            
        optim.step()
        optim.zero_grad()

    # Reduce metrics
    if len(metrics):
        assert not any(v.requires_grad for v in metrics.values())

        metric_keys = list(sorted(metrics.keys()))  # Sort keys to guarantee all processes use the same order.
        # Reduce and reconstruct
        metric_values = torch.stack([metrics[k] for k in metric_keys])
        if world_size > 1:
            dist.reduce(metric_values, dst=0)

        if rank == 0:
            metric_values = metric_values.cpu().numpy()
            reduced_metrics = {k: metric_values[i] for i, k in enumerate(metric_keys)}
            
            # Postprocess
            count = max(reduced_metrics["count"], 1)  # Avoid NaNs
            reduced_metrics = {f"train/{k}": v / (global_batch_size if k.endswith("loss") else count) for k, v in reduced_metrics.items()}

            reduced_metrics["train/lr"] = lr_this_step
            return reduced_metrics
```

**è®­ç»ƒæ­¥éª¤è¯¦è§£**ï¼š

1. **åˆå§‹åŒ– carry**ï¼š
   - `carry` æ˜¯æ¨¡å‹çš„çŠ¶æ€ï¼ˆç”¨äºé€’å½’æ¨ç†ï¼‰
   - ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶åˆå§‹åŒ–ï¼Œä¹‹ååœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¿æŒ

2. **å‰å‘ä¼ æ’­**ï¼š
   - æ¨¡å‹è¿”å›ï¼š`carry, loss, metrics, _, _`
   - `carry` ä¼šè¢«æ›´æ–°å¹¶ä¿å­˜åˆ° `train_state.carry`

3. **åå‘ä¼ æ’­**ï¼š
   - æŸå¤±é™¤ä»¥ `global_batch_size`ï¼ˆæ¢¯åº¦ç´¯ç§¯ï¼‰
   - ç„¶åè°ƒç”¨ `backward()`

4. **æ¢¯åº¦åŒæ­¥ï¼ˆåˆ†å¸ƒå¼ï¼‰**ï¼š
   - å¦‚æœå¤š GPUï¼Œä½¿ç”¨ `all_reduce` åŒæ­¥æ¢¯åº¦
   - æ‰€æœ‰è¿›ç¨‹çš„æ¢¯åº¦ä¼šè¢«æ±‚å’Œ

5. **ä¼˜åŒ–å™¨æ›´æ–°**ï¼š
   - è®¡ç®—å½“å‰æ­¥çš„å­¦ä¹ ç‡ï¼ˆå¸¦ warmup çš„ä½™å¼¦é€€ç«ï¼‰
   - æ›´æ–°æ‰€æœ‰ä¼˜åŒ–å™¨
   - æ¸…é›¶æ¢¯åº¦

6. **æŒ‡æ ‡èšåˆ**ï¼š
   - æ”¶é›†æ‰€æœ‰æŒ‡æ ‡
   - åœ¨å¤š GPU æ—¶ï¼Œreduce åˆ° rank 0
   - åªåœ¨ rank 0 è¿”å›æŒ‡æ ‡ï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰

### å­¦ä¹ ç‡è°ƒåº¦

```207:214:pretrain.py
def cosine_schedule_with_warmup_lr_lambda(
    current_step: int, *, base_lr: float, num_warmup_steps: int, num_training_steps: int, min_ratio: float = 0.0, num_cycles: float = 0.5
):
    if current_step < num_warmup_steps:
        return base_lr * float(current_step) / float(max(1, num_warmup_steps))

    progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))
    return base_lr * (min_ratio + max(0.0, (1 - min_ratio) * 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))))
```

**å­¦ä¹ ç‡ç­–ç•¥**ï¼š
- **Warmup é˜¶æ®µ**ï¼šçº¿æ€§å¢é•¿åˆ° `base_lr`
- **ä½™å¼¦é€€ç«**ï¼šä» `base_lr` è¡°å‡åˆ° `base_lr * min_ratio`
- `num_cycles=0.5` è¡¨ç¤ºåŠä¸ªä½™å¼¦å‘¨æœŸ

---

## è¯„ä¼°æµç¨‹

### evaluate

```345:486:pretrain.py
def evaluate(
    config: PretrainConfig,
    train_state: TrainState,
    eval_loader: torch.utils.data.DataLoader,
    eval_metadata: PuzzleDatasetMetadata,
    evaluators: List[Any],
    rank: int,
    world_size: int,
    cpu_group: Optional[dist.ProcessGroup],
):
    reduced_metrics = None

    with torch.inference_mode():
        return_keys = set(config.eval_save_outputs)
        for evaluator in evaluators:
            evaluator.begin_eval()
            return_keys.update(evaluator.required_outputs)

        # Run evaluation
        set_ids = {k: idx for idx, k in enumerate(eval_metadata.sets)}
        save_preds = {}
        metric_keys = []
        metric_values = None
        carry = None
        processed_batches = 0
        
        for set_name, batch, global_batch_size in eval_loader:
            processed_batches += 1
            if rank == 0:
                print(f"Processing batch {processed_batches}: {set_name}")
            
            # To device
            batch = {k: v.cuda() for k, v in batch.items()}
            with torch.device("cuda"):
                carry = train_state.model.initial_carry(batch)  # type: ignore

            # Forward
            inference_steps = 0
            while True:
                carry, loss, metrics, preds, all_finish = train_state.model(
                    carry=carry, batch=batch, return_keys=return_keys
                )
                inference_steps += 1

                if all_finish:
                    break

            if rank == 0:
                print(f"  Completed inference in {inference_steps} steps")

            for collection in (batch, preds):
                for k, v in collection.items():
                    if k in config.eval_save_outputs:
                        save_preds.setdefault(k, [])
                        save_preds[k].append(v.cpu())  # Move to CPU for saving GPU memory

            for evaluator in evaluators:
                evaluator.update_batch(batch, preds)

            del carry, loss, preds, batch, all_finish

            # Aggregate metrics
            set_id = set_ids[set_name]
            if metric_values is None:
                metric_keys = list(sorted(metrics.keys()))
                metric_values = torch.zeros(
                    (len(set_ids), len(metrics.values())), dtype=torch.float32, device="cuda"
                )
            metric_values[set_id] += torch.stack([metrics[k] for k in metric_keys])
            del metrics

        # ... ä¿å­˜é¢„æµ‹ç»“æœã€èšåˆæŒ‡æ ‡ã€è¿è¡Œè¯„ä¼°å™¨ ...
```

**è¯„ä¼°å…³é”®ç‚¹**ï¼š

1. **æ¨ç†æ¨¡å¼**ï¼š
   - ä½¿ç”¨ `torch.inference_mode()` ç¦ç”¨æ¢¯åº¦è®¡ç®—

2. **é€’å½’æ¨ç†å¾ªç¯**ï¼š
   ```python
   while True:
       carry, loss, metrics, preds, all_finish = model(...)
       if all_finish:
           break
   ```
   - æ¨¡å‹ä¼šé€’å½’æ¨ç†ç›´åˆ° `all_finish=True`
   - è¿™æ˜¯ TRM çš„æ ¸å¿ƒï¼šæ¨¡å‹ä¼šå¤šæ¬¡è¿­ä»£æ”¹è¿›ç­”æ¡ˆ

3. **è¯„ä¼°å™¨**ï¼š
   - æ¯ä¸ª batch åè°ƒç”¨ `evaluator.update_batch()`
   - æœ€åè°ƒç”¨ `evaluator.result()` è®¡ç®—æœ€ç»ˆæŒ‡æ ‡ï¼ˆå¦‚ ARC å‡†ç¡®ç‡ï¼‰

---

## ä¸»å‡½æ•°

### launch

```535:654:pretrain.py
@hydra.main(config_path="config", config_name="cfg_pretrain", version_base=None)
def launch(hydra_config: DictConfig):
    RANK = 0
    WORLD_SIZE = 1
    CPU_PROCESS_GROUP = None

    # Initialize distributed training if in distributed environment (e.g. torchrun)
    if "LOCAL_RANK" in os.environ:
        # Initialize distributed, default device and dtype
        dist.init_process_group(backend="nccl")
        RANK = dist.get_rank()
        WORLD_SIZE = dist.get_world_size()
        torch.cuda.set_device(int(os.environ["LOCAL_RANK"]))
        
        # CPU GLOO process group
        CPU_PROCESS_GROUP = dist.new_group(backend="gloo")
        assert (
            dist.get_rank(CPU_PROCESS_GROUP) == RANK and dist.get_world_size(CPU_PROCESS_GROUP) == WORLD_SIZE
        )

    # Load sync'ed config
    config = load_synced_config(hydra_config, rank=RANK, world_size=WORLD_SIZE)

    # Seed RNGs to ensure consistency
    torch.random.manual_seed(config.seed + RANK)

    # Dataset
    train_epochs_per_iter = config.eval_interval if config.eval_interval is not None else config.epochs
    total_iters = config.epochs // train_epochs_per_iter

    assert config.epochs % train_epochs_per_iter == 0, "Eval interval must be a divisor of total epochs."

    train_loader, train_metadata = create_dataloader(config, "train", test_set_mode=False, epochs_per_iter=train_epochs_per_iter, global_batch_size=config.global_batch_size, rank=RANK, world_size=WORLD_SIZE)
    try:
        eval_loader,  eval_metadata  = create_dataloader(config, "test", test_set_mode=True, epochs_per_iter=1, global_batch_size=config.global_batch_size, rank=RANK, world_size=WORLD_SIZE)
    except:
        print("NO EVAL DATA FOUND")
        eval_loader = eval_metadata = None

    try:
        evaluators = create_evaluators(config, eval_metadata)
    except:
        print("No evaluator found")
        evaluators = []

    # Train state
    train_state = init_train_state(config, train_metadata, rank=RANK, world_size=WORLD_SIZE)

    # Progress bar and logger
    progress_bar = None
    ema_helper = None
    if RANK == 0:
        progress_bar = tqdm.tqdm(total=train_state.total_steps)
        wandb.init(project=config.project_name, name=config.run_name, config=config.model_dump(), settings=wandb.Settings(_disable_stats=True))  # type: ignore
        wandb.log({"num_params": sum(x.numel() for x in train_state.model.parameters())}, step=0)
        save_code_and_config(config)
    if config.ema:
        print('Setup EMA')
        ema_helper = EMAHelper(mu=config.ema_rate)
        ema_helper.register(train_state.model)

    # Training Loop
    for _iter_id in range(total_iters):
        print (f"[Rank {RANK}, World Size {WORLD_SIZE}]: Epoch {_iter_id * train_epochs_per_iter}")

        ############ Train Iter
        if RANK == 0:
            print("TRAIN")
        train_state.model.train()
        for set_name, batch, global_batch_size in train_loader:
            metrics = train_batch(config, train_state, batch, global_batch_size, rank=RANK, world_size=WORLD_SIZE)

            if RANK == 0 and metrics is not None:
                wandb.log(metrics, step=train_state.step)
                progress_bar.update(train_state.step - progress_bar.n)  # type: ignore
            if config.ema:
                ema_helper.update(train_state.model)

        if _iter_id >= config.min_eval_interval:
            ############ Evaluation
            if RANK == 0:
                print("EVALUATE")
            if config.ema:
                print("SWITCH TO EMA")
                train_state_eval = copy.deepcopy(train_state)
                train_state_eval.model = ema_helper.ema_copy(train_state_eval.model)
            else:
                train_state_eval = train_state
            train_state_eval.model.eval()
            metrics = evaluate(config, 
                train_state_eval, 
                eval_loader, 
                eval_metadata, 
                evaluators,
                rank=RANK, 
                world_size=WORLD_SIZE,
                cpu_group=CPU_PROCESS_GROUP)

            if RANK == 0 and metrics is not None:
                wandb.log(metrics, step=train_state.step)
                
            ############ Checkpointing
            if RANK == 0:
                print("SAVE CHECKPOINT")
            if RANK == 0 and (config.checkpoint_every_eval or (_iter_id == total_iters - 1)):
                save_train_state(config, train_state_eval)

            if config.ema:
                del train_state_eval

    # finalize
    if dist.is_initialized():
        dist.destroy_process_group()
    wandb.finish()
```

**ä¸»æµç¨‹**ï¼š

1. **åˆ†å¸ƒå¼åˆå§‹åŒ–**ï¼š
   - æ£€æŸ¥ `LOCAL_RANK` ç¯å¢ƒå˜é‡ï¼ˆç”± `torchrun` è®¾ç½®ï¼‰
   - åˆå§‹åŒ– NCCLï¼ˆGPU é€šä¿¡ï¼‰å’Œ GLOOï¼ˆCPU é€šä¿¡ï¼‰è¿›ç¨‹ç»„

2. **é…ç½®åŠ è½½**ï¼š
   - Rank 0 åŠ è½½é…ç½®å¹¶å¹¿æ’­åˆ°å…¶ä»–è¿›ç¨‹

3. **æ•°æ®åŠ è½½**ï¼š
   - åˆ›å»ºè®­ç»ƒå’Œæµ‹è¯•æ•°æ®åŠ è½½å™¨
   - å¦‚æœæµ‹è¯•æ•°æ®ä¸å­˜åœ¨ï¼Œç»§ç»­è®­ç»ƒä½†ä¸è¯„ä¼°

4. **åˆå§‹åŒ–è®­ç»ƒçŠ¶æ€**ï¼š
   - åˆ›å»ºæ¨¡å‹ã€ä¼˜åŒ–å™¨
   - åˆå§‹åŒ– WandBï¼ˆåªåœ¨ rank 0ï¼‰
   - å¦‚æœå¯ç”¨ EMAï¼Œåˆ›å»º EMA helper

5. **è®­ç»ƒå¾ªç¯**ï¼š
   - æ¯ä¸ª iteration è®­ç»ƒ `train_epochs_per_iter` ä¸ª epoch
   - è®­ç»ƒåå¦‚æœè¾¾åˆ°è¯„ä¼°é—´éš”ï¼Œè¿›è¡Œè¯„ä¼°
   - å¦‚æœå¯ç”¨ EMAï¼Œè¯„ä¼°æ—¶ä½¿ç”¨ EMA ç‰ˆæœ¬çš„æ¨¡å‹

6. **æ£€æŸ¥ç‚¹ä¿å­˜**ï¼š
   - æ ¹æ®é…ç½®ä¿å­˜æ¨¡å‹æƒé‡

---

## å…³é”®è®¾è®¡ç‰¹ç‚¹

### 1. é€’å½’æ¨ç†çš„ carry æœºåˆ¶

`carry` æ˜¯æ¨¡å‹çš„çŠ¶æ€ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¿æŒï¼š
- è®­ç»ƒæ—¶ï¼šæ¯ä¸ª batch æ›´æ–° `carry`
- è¯„ä¼°æ—¶ï¼šæ¯ä¸ª batch é‡æ–°åˆå§‹åŒ– `carry`ï¼Œç„¶åé€’å½’æ¨ç†ç›´åˆ°å®Œæˆ

### 2. åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ

- **æ•°æ®å¹¶è¡Œ**ï¼šæ¯ä¸ªè¿›ç¨‹å¤„ç†ä¸åŒçš„æ•°æ®åˆ†ç‰‡
- **æ¢¯åº¦åŒæ­¥**ï¼šä½¿ç”¨ `all_reduce` åŒæ­¥æ¢¯åº¦
- **å‚æ•°åŒæ­¥**ï¼šåˆå§‹åŒ–æ—¶ä» rank 0 å¹¿æ’­å‚æ•°

### 3. EMAï¼ˆæŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼‰

- è®­ç»ƒæ—¶æŒç»­æ›´æ–° EMA æƒé‡
- è¯„ä¼°æ—¶ä½¿ç”¨ EMA ç‰ˆæœ¬çš„æ¨¡å‹ï¼ˆé€šå¸¸æ€§èƒ½æ›´å¥½ï¼‰

### 4. çµæ´»çš„ä¼˜åŒ–å™¨é…ç½®

- æ”¯æŒåªè®­ç»ƒ puzzle embedding
- æ”¯æŒå†»ç»“æƒé‡åªè®­ç»ƒ embedding
- æ”¯æŒåŒæ—¶è®­ç»ƒ embedding å’Œæ¨¡å‹æƒé‡

### 5. Hydra é…ç½®ç®¡ç†

- ä½¿ç”¨ Hydra è¿›è¡Œé…ç½®ç®¡ç†
- æ”¯æŒå‘½ä»¤è¡Œè¦†ç›–é…ç½®
- è‡ªåŠ¨ä¿å­˜é…ç½®åˆ°æ£€æŸ¥ç‚¹ç›®å½•

---

## ä½¿ç”¨ç¤ºä¾‹

```bash
# å• GPU è®­ç»ƒ
python pretrain.py \
  arch=trm \
  data_paths="[data/arc1concept-aug-1000]" \
  +run_name=my_run \
  ema=True

# å¤š GPU è®­ç»ƒ
torchrun --nproc-per-node 4 pretrain.py \
  arch=trm \
  data_paths="[data/arc1concept-aug-1000]" \
  +run_name=my_run \
  ema=True
```

---

## å¸¸è§é—®é¢˜

### Q: ä¸ºä»€ä¹ˆ `batch_size=None`ï¼Ÿ
A: `PuzzleDataset` è‡ªå·±å¤„ç†æ‰¹æ¬¡æ„å»ºï¼Œè¿”å›çš„æ¯ä¸ª item å·²ç»æ˜¯ä¸€ä¸ª batchã€‚

### Q: carry æ˜¯ä»€ä¹ˆï¼Ÿ
A: æ¨¡å‹çš„çŠ¶æ€ï¼Œç”¨äºé€’å½’æ¨ç†ã€‚è®­ç»ƒæ—¶ä¿æŒï¼Œè¯„ä¼°æ—¶æ¯ä¸ª batch é‡æ–°åˆå§‹åŒ–ã€‚

### Q: å¦‚ä½•ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒï¼Ÿ
A: ä½¿ç”¨ `load_checkpoint=path/to/checkpoint` å‚æ•°ã€‚æ³¨æ„ï¼šå½“å‰ä»£ç åªä¿å­˜æ¨¡å‹æƒé‡ï¼Œä¸ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€ã€‚

### Q: EMA å¦‚ä½•å·¥ä½œï¼Ÿ
A: è®­ç»ƒæ—¶æŒç»­æ›´æ–° EMA æƒé‡ï¼ˆ`ema_helper.update()`ï¼‰ï¼Œè¯„ä¼°æ—¶åˆ›å»º EMA ç‰ˆæœ¬çš„æ¨¡å‹å‰¯æœ¬ã€‚

